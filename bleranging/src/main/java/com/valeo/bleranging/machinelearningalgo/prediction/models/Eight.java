/*
  Licensed under the Apache License, Version 2.0
    http://www.apache.org/licenses/LICENSE-2.0.html

  AUTOGENERATED BY H2O at 2017-06-13T17:54:23.304+02:00
  3.10.4.2
  
  Standalone prediction code with sample test data for DeepLearningModel named Eight

  How to download, compile and execute:
      mkdir tmpdir
      cd tmpdir
      curl http://127.0.0.1:54321/3/h2o-genmodel.jar > h2o-genmodel.jar
      curl http://127.0.0.1:54321/3/Models.java/Eight > Eight.java
      javac -cp h2o-genmodel.jar -J-Xmx2g -J-XX:MaxPermSize=128m Eight.java

     (Note:  Try java argument -XX:+PrintCompilation to show runtime JIT compiler behavior.)
*/
import hex.genmodel.GenModel;
import hex.genmodel.annotations.ModelPojo;

@ModelPojo(name = "Eight", algorithm = "deeplearning")
public class Eight extends GenModel {
  // Workspace for categorical offsets.
  public static final int[] CATOFFSETS = {0};
  // Number of neurons for each layer.
  public static final int[] NEURONS = {8, 16, 16, 7};
    // Neuron bias values.
    public static final double[][] BIAS = new double[][]{
      /* Input */ Eight_Bias_0.VALUES,
      /* Rectifier */ Eight_Bias_1.VALUES,
      /* Rectifier */ Eight_Bias_2.VALUES,
      /* Softmax */ Eight_Bias_3.VALUES
    };
    // Connecting weights between neurons.
    public static final float[][] WEIGHT = new float[][]{
      /* Input */ Eight_Weight_0.VALUES,
      /* Rectifier */ Eight_Weight_1.VALUES,
      /* Rectifier */ Eight_Weight_2.VALUES,
      /* Softmax */ Eight_Weight_3.VALUES
    };
  // Names of columns used by model.
  public static final String[] NAMES = NamesHolder_Eight.VALUES;
  // Number of output classes included in training data response column.
  public static final int NCLASSES = 7;
  // Column domains. The last array contains domain of response column.
  public static final String[][] DOMAINS = new String[][]{
    /* RSSI LEFT_ORIGIN */ null,
    /* RSSI MIDDLE_ORIGIN */ null,
    /* RSSI RIGHT_ORIGIN */ null,
    /* RSSI TRUNK_ORIGIN */ null,
    /* RSSI FRONTLEFT_ORIGIN */ null,
    /* RSSI FRONTRIGHT_ORIGIN */ null,
    /* RSSI REARLEFT_ORIGIN */ null,
    /* RSSI REARRIGHT_ORIGIN */ null,
    /* class */ Eight_ColInfo_8.VALUES
  };
  // Prior class distribution
  public static final double[] PRIOR_CLASS_DISTRIB = {0.13043478260869565, 0.13043478260869565, 0.13043478260869565, 0.13043478260869565, 0.13043478260869565, 0.21739130434782608, 0.13043478260869565};
  // Class distribution used for model building
  public static final double[] MODEL_CLASS_DISTRIB = null;
  // Thread-local storage for input neuron activation values.
  final double[] NUMS = new double[8];
    // Thread-local storage for neuron activation values.
    final double[][] ACTIVATION = new double[][]{
      /* Input */ Eight_Activation_0.VALUES,
      /* Rectifier */ Eight_Activation_1.VALUES,
      /* Rectifier */ Eight_Activation_2.VALUES,
      /* Softmax */ Eight_Activation_3.VALUES
    };

  public Eight() {
    super(NAMES, DOMAINS);
  }

  public hex.ModelCategory getModelCategory() {
    return hex.ModelCategory.Multinomial;
  }

  public boolean isSupervised() {
    return true;
  }

  public int nfeatures() {
    return 8;
  }

  public int nclasses() {
    return 7;
  }

  public String getUUID() {
    return Long.toString(-928398519807630208L);
  }

  // Pass in data in a double[], pre-aligned to the Model's requirements.
  // Jam predictions into the preds[] array; preds[0] is reserved for the
  // main prediction (class for classifiers or value for regression),
  // and remaining columns hold a probability distribution for classifiers.
  public final double[] score0(double[] data, double[] preds) {
    java.util.Arrays.fill(preds, 0);
    java.util.Arrays.fill(NUMS, 0);
    int i = 0, ncats = 0;
    final int n = data.length;
    for (; i < n; ++i) {
      NUMS[i] = Double.isNaN(data[i]) ? 0 : (data[i] - NORMSUB.VALUES[i]) * NORMMUL.VALUES[i];
    }
    java.util.Arrays.fill(ACTIVATION[0], 0);
    for (i = 0; i < NUMS.length; ++i) {
      ACTIVATION[0][CATOFFSETS[CATOFFSETS.length - 1] + i] = Double.isNaN(NUMS[i]) ? 0 : NUMS[i];
    }
    for (i = 1; i < ACTIVATION.length; ++i) {
      java.util.Arrays.fill(ACTIVATION[i], 0);
      int cols = ACTIVATION[i - 1].length;
      int rows = ACTIVATION[i].length;
      int extra = cols - cols % 8;
      int multiple = (cols / 8) * 8 - 1;
      int idx = 0;
      float[] a = WEIGHT[i];
      double[] x = ACTIVATION[i - 1];
      double[] y = BIAS[i];
      double[] res = ACTIVATION[i];
      for (int row = 0; row < rows; ++row) {
        double psum0 = 0, psum1 = 0, psum2 = 0, psum3 = 0, psum4 = 0, psum5 = 0, psum6 = 0, psum7 = 0;
        for (int col = 0; col < multiple; col += 8) {
          int off = idx + col;
          psum0 += a[off] * x[col];
          psum1 += a[off + 1] * x[col + 1];
          psum2 += a[off + 2] * x[col + 2];
          psum3 += a[off + 3] * x[col + 3];
          psum4 += a[off + 4] * x[col + 4];
          psum5 += a[off + 5] * x[col + 5];
          psum6 += a[off + 6] * x[col + 6];
          psum7 += a[off + 7] * x[col + 7];
        }
        res[row] += psum0 + psum1 + psum2 + psum3;
        res[row] += psum4 + psum5 + psum6 + psum7;
        for (int col = extra; col < cols; col++)
          res[row] += a[idx + col] * x[col];
        res[row] += y[row];
        idx += cols;
      }
      if (i < ACTIVATION.length - 1) {
        for (int r = 0; r < ACTIVATION[i].length; ++r) {
          ACTIVATION[i][r] = Math.max(0, ACTIVATION[i][r]);
        }
      }
      if (i == ACTIVATION.length - 1) {
        double max = ACTIVATION[i][0];
        for (int r = 1; r < ACTIVATION[i].length; r++) {
          if (ACTIVATION[i][r] > max) max = ACTIVATION[i][r];
        }
        double scale = 0;
        for (int r = 0; r < ACTIVATION[i].length; r++) {
          ACTIVATION[i][r] = Math.exp(ACTIVATION[i][r] - max);
          scale += ACTIVATION[i][r];
        }
        for (int r = 0; r < ACTIVATION[i].length; r++) {
          if (Double.isNaN(ACTIVATION[i][r]))
            throw new RuntimeException("Numerical instability, predicted NaN.");
          ACTIVATION[i][r] /= scale;
          preds[r + 1] = ACTIVATION[i][r];
        }
      }
    }
    preds[0] = hex.genmodel.GenModel.getPrediction(preds, PRIOR_CLASS_DISTRIB, data, 0.5);
    return preds;
  }

  static class NORMMUL implements java.io.Serializable {
    public static final double[] VALUES = new double[8];

    static {
      NORMMUL_0.fill(VALUES);
    }

    static final class NORMMUL_0 implements java.io.Serializable {
      static final void fill(double[] sa) {
        sa[0] = 0.11729114794459763;
        sa[1] = 0.0922516089217261;
        sa[2] = 0.11306328687392926;
        sa[3] = 0.08053634042738825;
        sa[4] = 0.1413834469076605;
        sa[5] = 0.11104995454859523;
        sa[6] = 0.11297029708276866;
        sa[7] = 0.11203395571572401;
      }
    }
  }

  static class NORMSUB implements java.io.Serializable {
    public static final double[] VALUES = new double[8];

    static {
      NORMSUB_0.fill(VALUES);
    }

    static final class NORMSUB_0 implements java.io.Serializable {
      static final void fill(double[] sa) {
        sa[0] = -74.73054347826086;
        sa[1] = -73.81747282608698;
        sa[2] = -77.47105978260869;
        sa[3] = -70.10644021739131;
        sa[4] = -81.18228260869566;
        sa[5] = -84.40274456521739;
        sa[6] = -78.67749999999998;
        sa[7] = -79.47758152173914;
      }
    }
  }
}

// Neuron activation values for Input layer
class Eight_Activation_0 implements java.io.Serializable {
  public static final double[] VALUES = new double[8];

  static {
    Eight_Activation_0_0.fill(VALUES);
  }

  static final class Eight_Activation_0_0 implements java.io.Serializable {
    static final void fill(double[] sa) {
      sa[0] = 0.0;
      sa[1] = 0.0;
      sa[2] = 0.0;
      sa[3] = 0.0;
      sa[4] = 0.0;
      sa[5] = 0.0;
      sa[6] = 0.0;
      sa[7] = 0.0;
    }
  }
}
// Neuron activation values for Rectifier layer
class Eight_Activation_1 implements java.io.Serializable {
  public static final double[] VALUES = new double[16];

  static {
    Eight_Activation_1_0.fill(VALUES);
  }

  static final class Eight_Activation_1_0 implements java.io.Serializable {
    static final void fill(double[] sa) {
      sa[0] = 0.0;
      sa[1] = 0.0;
      sa[2] = 0.0;
      sa[3] = 0.0;
      sa[4] = 0.0;
      sa[5] = 0.0;
      sa[6] = 0.0;
      sa[7] = 0.0;
      sa[8] = 0.0;
      sa[9] = 0.0;
      sa[10] = 0.0;
      sa[11] = 0.0;
      sa[12] = 0.0;
      sa[13] = 0.0;
      sa[14] = 0.0;
      sa[15] = 0.0;
    }
  }
}
// Neuron activation values for Rectifier layer
class Eight_Activation_2 implements java.io.Serializable {
  public static final double[] VALUES = new double[16];

  static {
    Eight_Activation_2_0.fill(VALUES);
  }

  static final class Eight_Activation_2_0 implements java.io.Serializable {
    static final void fill(double[] sa) {
      sa[0] = 0.0;
      sa[1] = 0.0;
      sa[2] = 0.0;
      sa[3] = 0.0;
      sa[4] = 0.0;
      sa[5] = 0.0;
      sa[6] = 0.0;
      sa[7] = 0.0;
      sa[8] = 0.0;
      sa[9] = 0.0;
      sa[10] = 0.0;
      sa[11] = 0.0;
      sa[12] = 0.0;
      sa[13] = 0.0;
      sa[14] = 0.0;
      sa[15] = 0.0;
    }
  }
}
// Neuron activation values for Softmax layer
class Eight_Activation_3 implements java.io.Serializable {
  public static final double[] VALUES = new double[7];

  static {
    Eight_Activation_3_0.fill(VALUES);
  }

  static final class Eight_Activation_3_0 implements java.io.Serializable {
    static final void fill(double[] sa) {
      sa[0] = 0.0;
      sa[1] = 0.0;
      sa[2] = 0.0;
      sa[3] = 0.0;
      sa[4] = 0.0;
      sa[5] = 0.0;
      sa[6] = 0.0;
    }
  }
}
// Neuron bias values for Input layer
class Eight_Bias_0 implements java.io.Serializable {
  public static final double[] VALUES = null;
}
// Neuron bias values for Rectifier layer
class Eight_Bias_1 implements java.io.Serializable {
  public static final double[] VALUES = new double[16];

  static {
    Eight_Bias_1_0.fill(VALUES);
  }

  static final class Eight_Bias_1_0 implements java.io.Serializable {
    static final void fill(double[] sa) {
      sa[0] = 0.7518297376964186;
      sa[1] = 0.6481070779396686;
      sa[2] = -0.21025579049807616;
      sa[3] = 0.4423664102166761;
      sa[4] = 0.46681029045929906;
      sa[5] = 1.1382751602942174;
      sa[6] = 0.6878592018546767;
      sa[7] = 1.184337806529298;
      sa[8] = 0.24883938068693215;
      sa[9] = 0.9863576337333145;
      sa[10] = 0.8350535874907942;
      sa[11] = 0.3045576891548628;
      sa[12] = 0.017429897284186202;
      sa[13] = 0.7272536320466683;
      sa[14] = 0.4027308813069835;
      sa[15] = 0.2871392464892822;
    }
  }
}
// Neuron bias values for Rectifier layer
class Eight_Bias_2 implements java.io.Serializable {
  public static final double[] VALUES = new double[16];

  static {
    Eight_Bias_2_0.fill(VALUES);
  }

  static final class Eight_Bias_2_0 implements java.io.Serializable {
    static final void fill(double[] sa) {
      sa[0] = 0.9378604749814556;
      sa[1] = 1.3602449218730375;
      sa[2] = 0.5716263006971359;
      sa[3] = 0.9254671896685263;
      sa[4] = 0.9575930240500959;
      sa[5] = 1.0839274202438391;
      sa[6] = 0.35536200478957014;
      sa[7] = 1.157600435826749;
      sa[8] = 0.776928372666103;
      sa[9] = 1.0387211574644042;
      sa[10] = 1.0724347828168241;
      sa[11] = 0.6177723312348761;
      sa[12] = 1.2075354249527206;
      sa[13] = 1.6451406849419903;
      sa[14] = 1.2633492282860705;
      sa[15] = 1.2887161275407306;
    }
  }
}
// Neuron bias values for Softmax layer
class Eight_Bias_3 implements java.io.Serializable {
  public static final double[] VALUES = new double[7];

  static {
    Eight_Bias_3_0.fill(VALUES);
  }

  static final class Eight_Bias_3_0 implements java.io.Serializable {
    static final void fill(double[] sa) {
      sa[0] = 0.4287940943195814;
      sa[1] = -0.018032427610071185;
      sa[2] = -0.2009159562909658;
      sa[3] = -0.012226535629168147;
      sa[4] = 0.03662862188469036;
      sa[5] = 0.25251121695215695;
      sa[6] = -0.1889895350998264;
    }
  }
}
class Eight_Weight_0 implements java.io.Serializable {
  public static final float[] VALUES = null;
}
// Neuron weights connecting Input and Rectifier layer
class Eight_Weight_1 implements java.io.Serializable {
  public static final float[] VALUES = new float[128];

  static {
    Eight_Weight_1_0.fill(VALUES);
  }

  static final class Eight_Weight_1_0 implements java.io.Serializable {
    static final void fill(float[] sa) {
      sa[0] = -0.5140202f;
      sa[1] = -0.31295085f;
      sa[2] = 0.1320655f;
      sa[3] = -0.23772906f;
      sa[4] = -0.6935629f;
      sa[5] = -0.040729415f;
      sa[6] = -0.52679026f;
      sa[7] = 0.007775715f;
      sa[8] = -0.44147334f;
      sa[9] = -0.15573968f;
      sa[10] = 0.35113552f;
      sa[11] = -0.4674954f;
      sa[12] = 0.22316128f;
      sa[13] = 0.24522863f;
      sa[14] = -0.28671765f;
      sa[15] = 0.2809801f;
      sa[16] = -0.39232594f;
      sa[17] = 0.1708232f;
      sa[18] = 0.2870896f;
      sa[19] = 0.36786962f;
      sa[20] = -0.10849414f;
      sa[21] = 0.25485033f;
      sa[22] = 1.4462992f;
      sa[23] = -0.4165936f;
      sa[24] = -0.43060476f;
      sa[25] = -0.7882679f;
      sa[26] = 0.22221407f;
      sa[27] = -0.3067574f;
      sa[28] = -0.12696643f;
      sa[29] = 1.4621111f;
      sa[30] = -1.0867975f;
      sa[31] = -0.3298514f;
      sa[32] = -0.024857562f;
      sa[33] = 0.43752888f;
      sa[34] = 0.99956846f;
      sa[35] = 0.3219912f;
      sa[36] = 0.26049805f;
      sa[37] = 0.4399002f;
      sa[38] = -0.41436553f;
      sa[39] = 0.111624904f;
      sa[40] = -0.29000822f;
      sa[41] = -0.74078834f;
      sa[42] = -0.31414223f;
      sa[43] = 0.28809282f;
      sa[44] = 0.2801297f;
      sa[45] = -0.44416556f;
      sa[46] = 0.509253f;
      sa[47] = -0.3533135f;
      sa[48] = 0.3276732f;
      sa[49] = 0.45861617f;
      sa[50] = -0.28144455f;
      sa[51] = 1.2346126f;
      sa[52] = -1.1530741f;
      sa[53] = -1.4052795f;
      sa[54] = 0.6633199f;
      sa[55] = 0.5934839f;
      sa[56] = 1.1203775f;
      sa[57] = 0.040337153f;
      sa[58] = 0.3211087f;
      sa[59] = -0.44236746f;
      sa[60] = 0.121693544f;
      sa[61] = -0.96988046f;
      sa[62] = 0.28765097f;
      sa[63] = -0.45415518f;
      sa[64] = 0.40308148f;
      sa[65] = 0.12358265f;
      sa[66] = -0.7209508f;
      sa[67] = 0.19977951f;
      sa[68] = -0.2922061f;
      sa[69] = 0.12065646f;
      sa[70] = -0.6913003f;
      sa[71] = -0.41393375f;
      sa[72] = -0.23884933f;
      sa[73] = 0.26792097f;
      sa[74] = -0.065011755f;
      sa[75] = -0.106343895f;
      sa[76] = -0.15775506f;
      sa[77] = 0.362277f;
      sa[78] = -0.06325339f;
      sa[79] = 1.1256998f;
      sa[80] = 0.6764299f;
      sa[81] = 0.15898581f;
      sa[82] = 0.12534718f;
      sa[83] = -0.46171883f;
      sa[84] = 0.7783976f;
      sa[85] = -0.20344085f;
      sa[86] = -0.21138072f;
      sa[87] = -0.6812025f;
      sa[88] = -0.31813297f;
      sa[89] = 0.01587141f;
      sa[90] = -0.15579775f;
      sa[91] = 0.22545598f;
      sa[92] = 0.18214303f;
      sa[93] = 0.3426414f;
      sa[94] = -0.71382594f;
      sa[95] = 0.10985969f;
      sa[96] = -0.05937511f;
      sa[97] = -0.16793288f;
      sa[98] = 0.43644094f;
      sa[99] = 0.3995909f;
      sa[100] = 0.02334039f;
      sa[101] = -0.09908366f;
      sa[102] = -0.13629715f;
      sa[103] = 0.3722059f;
      sa[104] = 0.34269595f;
      sa[105] = -0.77234024f;
      sa[106] = 0.216607f;
      sa[107] = -0.1002556f;
      sa[108] = -0.009632041f;
      sa[109] = -0.40198314f;
      sa[110] = 0.17676266f;
      sa[111] = 0.5315477f;
      sa[112] = -0.08822708f;
      sa[113] = 0.685258f;
      sa[114] = -0.2640461f;
      sa[115] = 0.45300052f;
      sa[116] = 0.04340353f;
      sa[117] = 0.439567f;
      sa[118] = -0.022796007f;
      sa[119] = -0.86860156f;
      sa[120] = 0.14564887f;
      sa[121] = -0.57567614f;
      sa[122] = -0.2210639f;
      sa[123] = 0.9793801f;
      sa[124] = 0.3181941f;
      sa[125] = 0.116854325f;
      sa[126] = -0.39729986f;
      sa[127] = 0.70268095f;
    }
  }
}
// Neuron weights connecting Rectifier and Rectifier layer
class Eight_Weight_2 implements java.io.Serializable {
  public static final float[] VALUES = new float[256];

  static {
    Eight_Weight_2_0.fill(VALUES);
  }

  static final class Eight_Weight_2_0 implements java.io.Serializable {
    static final void fill(float[] sa) {
      sa[0] = 0.116378784f;
      sa[1] = 0.34840444f;
      sa[2] = -0.6793117f;
      sa[3] = 0.68134993f;
      sa[4] = 1.2197065f;
      sa[5] = 0.23042902f;
      sa[6] = -0.14532582f;
      sa[7] = 0.4786854f;
      sa[8] = 0.5293866f;
      sa[9] = 0.10022373f;
      sa[10] = 1.056326f;
      sa[11] = -0.014874262f;
      sa[12] = -0.12754793f;
      sa[13] = -0.28340405f;
      sa[14] = 0.55296487f;
      sa[15] = -0.68492925f;
      sa[16] = -0.054550845f;
      sa[17] = -0.34594247f;
      sa[18] = 1.0359235f;
      sa[19] = 0.0685594f;
      sa[20] = -0.3987289f;
      sa[21] = -0.0073223794f;
      sa[22] = 0.7991053f;
      sa[23] = -0.27433103f;
      sa[24] = 0.33121338f;
      sa[25] = 0.409826f;
      sa[26] = -0.4237706f;
      sa[27] = -0.11458698f;
      sa[28] = -0.018375114f;
      sa[29] = -0.19834134f;
      sa[30] = -0.60398585f;
      sa[31] = -0.20376441f;
      sa[32] = -0.35828313f;
      sa[33] = 0.4143177f;
      sa[34] = -0.2807519f;
      sa[35] = -0.31995857f;
      sa[36] = 0.2063298f;
      sa[37] = -0.6945142f;
      sa[38] = 0.21991077f;
      sa[39] = 0.6300069f;
      sa[40] = 0.50157356f;
      sa[41] = 0.123644345f;
      sa[42] = -0.24025087f;
      sa[43] = 0.30851376f;
      sa[44] = 0.296988f;
      sa[45] = -0.30323237f;
      sa[46] = 0.5299361f;
      sa[47] = 0.93710613f;
      sa[48] = 0.8726276f;
      sa[49] = 0.19583946f;
      sa[50] = -0.30383295f;
      sa[51] = 0.45191637f;
      sa[52] = 0.6014591f;
      sa[53] = 0.17320745f;
      sa[54] = 0.10882931f;
      sa[55] = -0.298071f;
      sa[56] = 0.5547809f;
      sa[57] = 0.43746975f;
      sa[58] = 0.2639513f;
      sa[59] = 0.77018476f;
      sa[60] = -0.22659221f;
      sa[61] = 0.365787f;
      sa[62] = 0.45790225f;
      sa[63] = 0.06067507f;
      sa[64] = 0.465387f;
      sa[65] = -1.0178945f;
      sa[66] = -0.02896341f;
      sa[67] = 0.25809318f;
      sa[68] = 0.18324459f;
      sa[69] = 0.13765772f;
      sa[70] = 0.2535841f;
      sa[71] = 0.03708287f;
      sa[72] = -0.018901438f;
      sa[73] = 0.60531145f;
      sa[74] = -0.35095102f;
      sa[75] = 0.063312426f;
      sa[76] = 0.21552475f;
      sa[77] = -0.005742773f;
      sa[78] = 0.22417891f;
      sa[79] = -0.030151932f;
      sa[80] = 0.7853864f;
      sa[81] = -0.48061016f;
      sa[82] = 0.10840222f;
      sa[83] = 0.22950177f;
      sa[84] = 0.55343246f;
      sa[85] = 0.1097994f;
      sa[86] = -0.47923863f;
      sa[87] = 0.5851903f;
      sa[88] = 0.254959f;
      sa[89] = 0.65466034f;
      sa[90] = -0.29709974f;
      sa[91] = 0.035199497f;
      sa[92] = 0.4590552f;
      sa[93] = -0.5034973f;
      sa[94] = -0.20501287f;
      sa[95] = -0.23729844f;
      sa[96] = 0.65683335f;
      sa[97] = -0.55164784f;
      sa[98] = 0.3141142f;
      sa[99] = 0.24992943f;
      sa[100] = 0.614055f;
      sa[101] = 0.08789052f;
      sa[102] = -0.24891149f;
      sa[103] = -0.25149006f;
      sa[104] = 0.090511404f;
      sa[105] = -0.22213972f;
      sa[106] = 0.21621585f;
      sa[107] = -0.071079284f;
      sa[108] = 0.011337112f;
      sa[109] = -0.006510733f;
      sa[110] = 0.16417092f;
      sa[111] = 0.25319612f;
      sa[112] = -0.050806887f;
      sa[113] = 0.24587488f;
      sa[114] = 0.239776f;
      sa[115] = 0.07905539f;
      sa[116] = -0.5714485f;
      sa[117] = -0.59415317f;
      sa[118] = -0.24800168f;
      sa[119] = 0.52215314f;
      sa[120] = 0.50151944f;
      sa[121] = 0.7060554f;
      sa[122] = -0.40604576f;
      sa[123] = -0.2596252f;
      sa[124] = 0.05555646f;
      sa[125] = -0.56156516f;
      sa[126] = 0.39040902f;
      sa[127] = 0.3413788f;
      sa[128] = 0.3263301f;
      sa[129] = 0.06228043f;
      sa[130] = 1.0533997f;
      sa[131] = -0.35745323f;
      sa[132] = 0.7439787f;
      sa[133] = -0.9169774f;
      sa[134] = -0.34514612f;
      sa[135] = 0.2945882f;
      sa[136] = -0.21733056f;
      sa[137] = 0.05247861f;
      sa[138] = 0.20194136f;
      sa[139] = 0.010551487f;
      sa[140] = 0.8494436f;
      sa[141] = -0.4409049f;
      sa[142] = 0.9401716f;
      sa[143] = 0.15598708f;
      sa[144] = -0.99747884f;
      sa[145] = 0.5994639f;
      sa[146] = 0.9900986f;
      sa[147] = -0.8176345f;
      sa[148] = 0.18964598f;
      sa[149] = 0.16086228f;
      sa[150] = 0.16530704f;
      sa[151] = 0.14367081f;
      sa[152] = 0.9170574f;
      sa[153] = 0.4675394f;
      sa[154] = -0.7371874f;
      sa[155] = 0.49066857f;
      sa[156] = -0.2622105f;
      sa[157] = 0.32753086f;
      sa[158] = 0.4310207f;
      sa[159] = 0.5636726f;
      sa[160] = 0.09922007f;
      sa[161] = -1.0985608f;
      sa[162] = -0.36591798f;
      sa[163] = 0.33116955f;
      sa[164] = -0.84656507f;
      sa[165] = 0.45352116f;
      sa[166] = 0.53341717f;
      sa[167] = -0.63513273f;
      sa[168] = 0.11644809f;
      sa[169] = 0.97684157f;
      sa[170] = 0.5071807f;
      sa[171] = 0.19069535f;
      sa[172] = 0.298394f;
      sa[173] = -0.29369214f;
      sa[174] = -0.5436041f;
      sa[175] = -0.3218001f;
      sa[176] = 0.09623222f;
      sa[177] = 0.22821823f;
      sa[178] = 0.7742535f;
      sa[179] = 0.0063131596f;
      sa[180] = -0.43985444f;
      sa[181] = -0.26207104f;
      sa[182] = 0.35308573f;
      sa[183] = 0.7854541f;
      sa[184] = 0.33213332f;
      sa[185] = 0.17223193f;
      sa[186] = -0.25313097f;
      sa[187] = 0.17338905f;
      sa[188] = 0.034693178f;
      sa[189] = 0.08159471f;
      sa[190] = -0.35452512f;
      sa[191] = -0.06826691f;
      sa[192] = -0.36190543f;
      sa[193] = 0.27459243f;
      sa[194] = -0.24098487f;
      sa[195] = 0.29731002f;
      sa[196] = 0.2347234f;
      sa[197] = -0.1282513f;
      sa[198] = 0.8819728f;
      sa[199] = 0.05634309f;
      sa[200] = 0.116072975f;
      sa[201] = -0.97899866f;
      sa[202] = 0.19232917f;
      sa[203] = -0.1637018f;
      sa[204] = -0.37948734f;
      sa[205] = -0.4744959f;
      sa[206] = 0.5464184f;
      sa[207] = -0.11923505f;
      sa[208] = -0.19323145f;
      sa[209] = 0.2446265f;
      sa[210] = -0.42393753f;
      sa[211] = -0.23285204f;
      sa[212] = 0.5301721f;
      sa[213] = 0.9251102f;
      sa[214] = -0.23270604f;
      sa[215] = 0.5145893f;
      sa[216] = 0.29884183f;
      sa[217] = 0.07299157f;
      sa[218] = -0.12875721f;
      sa[219] = 0.7377375f;
      sa[220] = -0.776377f;
      sa[221] = 0.0879401f;
      sa[222] = -0.12814152f;
      sa[223] = -0.46855125f;
      sa[224] = 0.50391114f;
      sa[225] = 0.30764666f;
      sa[226] = 0.20695281f;
      sa[227] = -0.30437014f;
      sa[228] = 0.10009247f;
      sa[229] = -0.07814751f;
      sa[230] = -0.33174208f;
      sa[231] = 0.4012556f;
      sa[232] = 0.28887466f;
      sa[233] = 0.063884325f;
      sa[234] = -0.3979302f;
      sa[235] = -0.07652781f;
      sa[236] = 1.2016684f;
      sa[237] = 0.27686787f;
      sa[238] = 0.92000324f;
      sa[239] = 0.78905857f;
      sa[240] = -0.26778764f;
      sa[241] = 0.76954556f;
      sa[242] = -0.25072262f;
      sa[243] = 0.9419741f;
      sa[244] = -0.37267143f;
      sa[245] = 0.27656633f;
      sa[246] = -0.5031683f;
      sa[247] = 0.80255985f;
      sa[248] = -0.15469208f;
      sa[249] = -0.025748735f;
      sa[250] = 0.5957835f;
      sa[251] = 0.6701548f;
      sa[252] = 0.21133417f;
      sa[253] = 0.68943244f;
      sa[254] = -0.65498275f;
      sa[255] = -0.7921734f;
    }
  }
}
// Neuron weights connecting Rectifier and Softmax layer
class Eight_Weight_3 implements java.io.Serializable {
  public static final float[] VALUES = new float[112];

  static {
    Eight_Weight_3_0.fill(VALUES);
  }

  static final class Eight_Weight_3_0 implements java.io.Serializable {
    static final void fill(float[] sa) {
      sa[0] = -2.632481f;
      sa[1] = 1.7038951f;
      sa[2] = -1.4092704f;
      sa[3] = -0.52312934f;
      sa[4] = -0.6796575f;
      sa[5] = 2.3301175f;
      sa[6] = -1.5924064f;
      sa[7] = 1.7004491f;
      sa[8] = -4.3196077f;
      sa[9] = -1.5745673f;
      sa[10] = 0.11020273f;
      sa[11] = 0.8572297f;
      sa[12] = -0.21714014f;
      sa[13] = 1.3584687f;
      sa[14] = 1.2370384f;
      sa[15] = -0.41424167f;
      sa[16] = -0.4228563f;
      sa[17] = -1.6360674f;
      sa[18] = -0.5601186f;
      sa[19] = 1.4175311f;
      sa[20] = 1.898695f;
      sa[21] = -2.7847111f;
      sa[22] = -0.27917165f;
      sa[23] = 2.1583002f;
      sa[24] = -1.7302018f;
      sa[25] = -6.0736604f;
      sa[26] = 0.598213f;
      sa[27] = -2.620922f;
      sa[28] = 2.115793f;
      sa[29] = 0.89536935f;
      sa[30] = 0.43445167f;
      sa[31] = 1.2124869f;
      sa[32] = -0.4661131f;
      sa[33] = -1.710557f;
      sa[34] = 1.0486693f;
      sa[35] = -0.43585587f;
      sa[36] = -3.020895f;
      sa[37] = -0.99291444f;
      sa[38] = -1.3843278f;
      sa[39] = 0.35403004f;
      sa[40] = -2.0861747f;
      sa[41] = 1.0955998f;
      sa[42] = -2.5048385f;
      sa[43] = 0.11430984f;
      sa[44] = 2.1030664f;
      sa[45] = 0.8169794f;
      sa[46] = 0.6758767f;
      sa[47] = 1.6820221f;
      sa[48] = 0.76045424f;
      sa[49] = -1.2868029f;
      sa[50] = -4.252162f;
      sa[51] = 1.6547737f;
      sa[52] = 1.2411726f;
      sa[53] = 0.68654937f;
      sa[54] = 0.9215132f;
      sa[55] = -3.7590766f;
      sa[56] = -1.3610066f;
      sa[57] = -1.475264f;
      sa[58] = 1.2909874f;
      sa[59] = 0.32597858f;
      sa[60] = -2.2962348f;
      sa[61] = 0.36471242f;
      sa[62] = -1.2743281f;
      sa[63] = 0.61549973f;
      sa[64] = 0.19977482f;
      sa[65] = -2.3382678f;
      sa[66] = -0.29762158f;
      sa[67] = 1.0946202f;
      sa[68] = -0.09475452f;
      sa[69] = 1.0943413f;
      sa[70] = 2.3574662f;
      sa[71] = -0.9525013f;
      sa[72] = 1.2960136f;
      sa[73] = -3.5273583f;
      sa[74] = -0.19083649f;
      sa[75] = 0.5318419f;
      sa[76] = -0.6334809f;
      sa[77] = -3.0947216f;
      sa[78] = 1.2896739f;
      sa[79] = 0.833804f;
      sa[80] = 0.0206311f;
      sa[81] = -2.8006158f;
      sa[82] = 1.4338143f;
      sa[83] = 1.5353501f;
      sa[84] = 0.64270985f;
      sa[85] = -0.44107664f;
      sa[86] = 2.6084023f;
      sa[87] = -0.23100781f;
      sa[88] = 0.635136f;
      sa[89] = 1.1617588f;
      sa[90] = -4.3193827f;
      sa[91] = 1.5544602f;
      sa[92] = -0.30945453f;
      sa[93] = 2.0757687f;
      sa[94] = -0.9109993f;
      sa[95] = -2.4233127f;
      sa[96] = -0.9113146f;
      sa[97] = 1.7304807f;
      sa[98] = 2.1415854f;
      sa[99] = -1.9102209f;
      sa[100] = -2.5253348f;
      sa[101] = -1.0002292f;
      sa[102] = 0.6443352f;
      sa[103] = 0.7367895f;
      sa[104] = -0.18139859f;
      sa[105] = 1.2117825f;
      sa[106] = -2.0690355f;
      sa[107] = 2.0422668f;
      sa[108] = -1.0030828f;
      sa[109] = -3.360438f;
      sa[110] = 0.93176717f;
      sa[111] = -0.38258657f;
    }
  }
}
// The class representing training column names
class NamesHolder_Eight implements java.io.Serializable {
  public static final String[] VALUES = new String[8];

  static {
    NamesHolder_Eight_0.fill(VALUES);
  }

  static final class NamesHolder_Eight_0 implements java.io.Serializable {
    static final void fill(String[] sa) {
      sa[0] = "RSSI LEFT_ORIGIN";
      sa[1] = "RSSI MIDDLE_ORIGIN";
      sa[2] = "RSSI RIGHT_ORIGIN";
      sa[3] = "RSSI TRUNK_ORIGIN";
      sa[4] = "RSSI FRONTLEFT_ORIGIN";
      sa[5] = "RSSI FRONTRIGHT_ORIGIN";
      sa[6] = "RSSI REARLEFT_ORIGIN";
      sa[7] = "RSSI REARRIGHT_ORIGIN";
    }
  }
}
// The class representing column class
class Eight_ColInfo_8 implements java.io.Serializable {
  public static final String[] VALUES = new String[7];

  static {
    Eight_ColInfo_8_0.fill(VALUES);
  }

  static final class Eight_ColInfo_8_0 implements java.io.Serializable {
    static final void fill(String[] sa) {
      sa[0] = "back";
      sa[1] = "front";
      sa[2] = "left";
      sa[3] = "lock";
      sa[4] = "right";
      sa[5] = "start";
      sa[6] = "trunk";
    }
  }
}

