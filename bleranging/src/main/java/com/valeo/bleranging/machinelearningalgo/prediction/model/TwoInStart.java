/*
  Licensed under the Apache License, Version 2.0
    http://www.apache.org/licenses/LICENSE-2.0.html

  AUTOGENERATED BY H2O at 2017-05-19T16:05:16.128+02:00
  3.10.4.2
  
  Standalone prediction code with sample test data for DeepLearningModel named TwoInStart

  How to download, compile and execute:
      mkdir tmpdir
      cd tmpdir
      curl http://127.0.0.1:54321/3/h2o-genmodel.jar > h2o-genmodel.jar
      curl http://127.0.0.1:54321/3/Models.java/TwoInStart > TwoInStart.java
      javac -cp h2o-genmodel.jar -J-Xmx2g -J-XX:MaxPermSize=128m TwoInStart.java

     (Note:  Try java argument -XX:+PrintCompilation to show runtime JIT compiler behavior.)
*/

import hex.genmodel.GenModel;
import hex.genmodel.annotations.ModelPojo;

@ModelPojo(name = "TwoInStart", algorithm = "deeplearning")
public class TwoInStart extends GenModel {
    // Workspace for categorical offsets.
    public static final int[] CATOFFSETS = {0};
    // Number of neurons for each layer.
    public static final int[] NEURONS = {2, 16, 16, 2};
    // Neuron bias values.
    public static final double[][] BIAS = new double[][]{
      /* Input */ TwoInStart_Bias_0.VALUES,
      /* Rectifier */ TwoInStart_Bias_1.VALUES,
      /* Rectifier */ TwoInStart_Bias_2.VALUES,
      /* Softmax */ TwoInStart_Bias_3.VALUES
    };
    // Connecting weights between neurons.
    public static final float[][] WEIGHT = new float[][]{
      /* Input */ TwoInStart_Weight_0.VALUES,
      /* Rectifier */ TwoInStart_Weight_1.VALUES,
      /* Rectifier */ TwoInStart_Weight_2.VALUES,
      /* Softmax */ TwoInStart_Weight_3.VALUES
    };
    // Names of columns used by model.
    public static final String[] NAMES = NamesHolder_TwoInStart.VALUES;
    // Number of output classes included in training data response column.
    public static final int NCLASSES = 2;
    // Column domains. The last array contains domain of response column.
    public static final String[][] DOMAINS = new String[][]{
    /* RSSI MIDDLE_ORIGIN */ null,
    /* RSSI TRUNK_ORIGIN */ null,
    /* class */ TwoInStart_ColInfo_2.VALUES
    };
    // Prior class distribution
    public static final double[] PRIOR_CLASS_DISTRIB = {0.42857142857142855, 0.5714285714285714};
    // Class distribution used for model building
    public static final double[] MODEL_CLASS_DISTRIB = null;
    // Thread-local storage for input neuron activation values.
    final double[] NUMS = new double[2];
    // Thread-local storage for neuron activation values.
    final double[][] ACTIVATION = new double[][]{
      /* Input */ TwoInStart_Activation_0.VALUES,
      /* Rectifier */ TwoInStart_Activation_1.VALUES,
      /* Rectifier */ TwoInStart_Activation_2.VALUES,
      /* Softmax */ TwoInStart_Activation_3.VALUES
    };

    public TwoInStart() {
        super(NAMES, DOMAINS);
    }

    public hex.ModelCategory getModelCategory() {
        return hex.ModelCategory.Binomial;
    }

    public boolean isSupervised() {
        return true;
    }

    public int nfeatures() {
        return 2;
    }

    public int nclasses() {
        return 2;
    }

    public String getUUID() {
        return Long.toString(-3499433551225419616L);
    }

    // Pass in data in a double[], pre-aligned to the Model's requirements.
    // Jam predictions into the preds[] array; preds[0] is reserved for the
    // main prediction (class for classifiers or value for regression),
    // and remaining columns hold a probability distribution for classifiers.
    public final double[] score0(double[] data, double[] preds) {
        java.util.Arrays.fill(preds, 0);
        java.util.Arrays.fill(NUMS, 0);
        int i = 0, ncats = 0;
        final int n = data.length;
        for (; i < n; ++i) {
            NUMS[i] = Double.isNaN(data[i]) ? 0 : (data[i] - NORMSUB.VALUES[i]) * NORMMUL.VALUES[i];
        }
        java.util.Arrays.fill(ACTIVATION[0], 0);
        for (i = 0; i < NUMS.length; ++i) {
            ACTIVATION[0][CATOFFSETS[CATOFFSETS.length - 1] + i] = Double.isNaN(NUMS[i]) ? 0 : NUMS[i];
        }
        for (i = 1; i < ACTIVATION.length; ++i) {
            java.util.Arrays.fill(ACTIVATION[i], 0);
            int cols = ACTIVATION[i - 1].length;
            int rows = ACTIVATION[i].length;
            int extra = cols - cols % 8;
            int multiple = (cols / 8) * 8 - 1;
            int idx = 0;
            float[] a = WEIGHT[i];
            double[] x = ACTIVATION[i - 1];
            double[] y = BIAS[i];
            double[] res = ACTIVATION[i];
            for (int row = 0; row < rows; ++row) {
                double psum0 = 0, psum1 = 0, psum2 = 0, psum3 = 0, psum4 = 0, psum5 = 0, psum6 = 0, psum7 = 0;
                for (int col = 0; col < multiple; col += 8) {
                    int off = idx + col;
                    psum0 += a[off] * x[col];
                    psum1 += a[off + 1] * x[col + 1];
                    psum2 += a[off + 2] * x[col + 2];
                    psum3 += a[off + 3] * x[col + 3];
                    psum4 += a[off + 4] * x[col + 4];
                    psum5 += a[off + 5] * x[col + 5];
                    psum6 += a[off + 6] * x[col + 6];
                    psum7 += a[off + 7] * x[col + 7];
                }
                res[row] += psum0 + psum1 + psum2 + psum3;
                res[row] += psum4 + psum5 + psum6 + psum7;
                for (int col = extra; col < cols; col++)
                    res[row] += a[idx + col] * x[col];
                res[row] += y[row];
                idx += cols;
            }
            if (i < ACTIVATION.length - 1) {
                for (int r = 0; r < ACTIVATION[i].length; ++r) {
                    ACTIVATION[i][r] = Math.max(0, ACTIVATION[i][r]);
                }
            }
            if (i == ACTIVATION.length - 1) {
                double max = ACTIVATION[i][0];
                for (int r = 1; r < ACTIVATION[i].length; r++) {
                    if (ACTIVATION[i][r] > max) max = ACTIVATION[i][r];
                }
                double scale = 0;
                for (int r = 0; r < ACTIVATION[i].length; r++) {
                    ACTIVATION[i][r] = Math.exp(ACTIVATION[i][r] - max);
                    scale += ACTIVATION[i][r];
                }
                for (int r = 0; r < ACTIVATION[i].length; r++) {
                    if (Double.isNaN(ACTIVATION[i][r]))
                        throw new RuntimeException("Numerical instability, predicted NaN.");
                    ACTIVATION[i][r] /= scale;
                    preds[r + 1] = ACTIVATION[i][r];
                }
            }
        }
        preds[0] = hex.genmodel.GenModel.getPrediction(preds, PRIOR_CLASS_DISTRIB, data, 0.36063562116630243);
        return preds;
    }

    static class NORMMUL implements java.io.Serializable {
        public static final double[] VALUES = new double[2];

        static {
            NORMMUL_0.fill(VALUES);
        }

        static final class NORMMUL_0 implements java.io.Serializable {
            static final void fill(double[] sa) {
                sa[0] = 0.1009973287502375;
                sa[1] = 0.0893635387252944;
            }
        }
    }

    static class NORMSUB implements java.io.Serializable {
        public static final double[] VALUES = new double[2];

        static {
            NORMSUB_0.fill(VALUES);
        }

        static final class NORMSUB_0 implements java.io.Serializable {
            static final void fill(double[] sa) {
                sa[0] = -73.45678571428573;
                sa[1] = -71.75504464285714;
            }
        }
    }


    // Neuron activation values for Input layer
    static class TwoInStart_Activation_0 implements java.io.Serializable {
        public static final double[] VALUES = new double[2];

        static {
            TwoInStart_Activation_0_0.fill(VALUES);
        }

        static final class TwoInStart_Activation_0_0 implements java.io.Serializable {
            static final void fill(double[] sa) {
                sa[0] = 0.0;
                sa[1] = 0.0;
            }
        }
    }

    // Neuron activation values for Rectifier layer
    static class TwoInStart_Activation_1 implements java.io.Serializable {
        public static final double[] VALUES = new double[16];

        static {
            TwoInStart_Activation_1_0.fill(VALUES);
        }

        static final class TwoInStart_Activation_1_0 implements java.io.Serializable {
            static final void fill(double[] sa) {
                sa[0] = 0.0;
                sa[1] = 0.0;
                sa[2] = 0.0;
                sa[3] = 0.0;
                sa[4] = 0.0;
                sa[5] = 0.0;
                sa[6] = 0.0;
                sa[7] = 0.0;
                sa[8] = 0.0;
                sa[9] = 0.0;
                sa[10] = 0.0;
                sa[11] = 0.0;
                sa[12] = 0.0;
                sa[13] = 0.0;
                sa[14] = 0.0;
                sa[15] = 0.0;
            }
        }
    }

    // Neuron activation values for Rectifier layer
    static class TwoInStart_Activation_2 implements java.io.Serializable {
        public static final double[] VALUES = new double[16];

        static {
            TwoInStart_Activation_2_0.fill(VALUES);
        }

        static final class TwoInStart_Activation_2_0 implements java.io.Serializable {
            static final void fill(double[] sa) {
                sa[0] = 0.0;
                sa[1] = 0.0;
                sa[2] = 0.0;
                sa[3] = 0.0;
                sa[4] = 0.0;
                sa[5] = 0.0;
                sa[6] = 0.0;
                sa[7] = 0.0;
                sa[8] = 0.0;
                sa[9] = 0.0;
                sa[10] = 0.0;
                sa[11] = 0.0;
                sa[12] = 0.0;
                sa[13] = 0.0;
                sa[14] = 0.0;
                sa[15] = 0.0;
            }
        }
    }

    // Neuron activation values for Softmax layer
    static class TwoInStart_Activation_3 implements java.io.Serializable {
        public static final double[] VALUES = new double[2];

        static {
            TwoInStart_Activation_3_0.fill(VALUES);
        }

        static final class TwoInStart_Activation_3_0 implements java.io.Serializable {
            static final void fill(double[] sa) {
                sa[0] = 0.0;
                sa[1] = 0.0;
            }
        }
    }

    // Neuron bias values for Input layer
    static class TwoInStart_Bias_0 implements java.io.Serializable {
        public static final double[] VALUES = null;
    }

    // Neuron bias values for Rectifier layer
    static class TwoInStart_Bias_1 implements java.io.Serializable {
        public static final double[] VALUES = new double[16];

        static {
            TwoInStart_Bias_1_0.fill(VALUES);
        }

        static final class TwoInStart_Bias_1_0 implements java.io.Serializable {
            static final void fill(double[] sa) {
                sa[0] = -0.03894518958130279;
                sa[1] = -0.014172509732858538;
                sa[2] = 1.7870885011371682;
                sa[3] = 0.0993957533858392;
                sa[4] = 0.4036931708693073;
                sa[5] = 0.770498145341536;
                sa[6] = -0.01280758424752311;
                sa[7] = 1.992258654928748;
                sa[8] = 0.008115915645881412;
                sa[9] = 0.056287306827273634;
                sa[10] = 2.882946573142554;
                sa[11] = 0.13707120338595807;
                sa[12] = 0.035655989623086845;
                sa[13] = -0.045667310545169607;
                sa[14] = 0.5316862473622214;
                sa[15] = 0.6645457517970274;
            }
        }
    }

    // Neuron bias values for Rectifier layer
    static class TwoInStart_Bias_2 implements java.io.Serializable {
        public static final double[] VALUES = new double[16];

        static {
            TwoInStart_Bias_2_0.fill(VALUES);
        }

        static final class TwoInStart_Bias_2_0 implements java.io.Serializable {
            static final void fill(double[] sa) {
                sa[0] = 1.0949887190430159;
                sa[1] = 1.0340021841309928;
                sa[2] = 1.0531341259705502;
                sa[3] = 0.8444389550469019;
                sa[4] = 0.9205875992402012;
                sa[5] = 0.9821427913930108;
                sa[6] = 0.8485440548450293;
                sa[7] = 0.8395681451211835;
                sa[8] = 0.8395635943820445;
                sa[9] = 0.9996513539944124;
                sa[10] = 1.1315113755516137;
                sa[11] = 0.9363834439708169;
                sa[12] = 1.2725854683773505;
                sa[13] = 0.667200897675992;
                sa[14] = 0.9730579483921926;
                sa[15] = 1.020720591392769;
            }
        }
    }

    // Neuron bias values for Softmax layer
    static class TwoInStart_Bias_3 implements java.io.Serializable {
        public static final double[] VALUES = new double[2];

        static {
            TwoInStart_Bias_3_0.fill(VALUES);
        }

        static final class TwoInStart_Bias_3_0 implements java.io.Serializable {
            static final void fill(double[] sa) {
                sa[0] = -0.20794911175419536;
                sa[1] = 0.21543062808148064;
            }
        }
    }

    static class TwoInStart_Weight_0 implements java.io.Serializable {
        public static final float[] VALUES = null;
    }

    // Neuron weights connecting Input and Rectifier layer
    static class TwoInStart_Weight_1 implements java.io.Serializable {
        public static final float[] VALUES = new float[32];

        static {
            TwoInStart_Weight_1_0.fill(VALUES);
        }

        static final class TwoInStart_Weight_1_0 implements java.io.Serializable {
            static final void fill(float[] sa) {
                sa[0] = -0.18312556f;
                sa[1] = -0.07831519f;
                sa[2] = -0.063825324f;
                sa[3] = -0.1963116f;
                sa[4] = 1.8586936f;
                sa[5] = -0.75266445f;
                sa[6] = -0.27072614f;
                sa[7] = 0.07850828f;
                sa[8] = -0.03685894f;
                sa[9] = 1.2318513f;
                sa[10] = 0.23910114f;
                sa[11] = -0.8811445f;
                sa[12] = -0.22434968f;
                sa[13] = 0.1721482f;
                sa[14] = 1.8440788f;
                sa[15] = 0.32615408f;
                sa[16] = -0.13177595f;
                sa[17] = -0.11924508f;
                sa[18] = -0.10443324f;
                sa[19] = -0.028199771f;
                sa[20] = 1.8385727f;
                sa[21] = 0.08475694f;
                sa[22] = -0.151804f;
                sa[23] = -0.21250792f;
                sa[24] = -0.09468577f;
                sa[25] = -0.10421142f;
                sa[26] = -0.08839684f;
                sa[27] = -0.2912645f;
                sa[28] = 0.11327053f;
                sa[29] = -0.6742176f;
                sa[30] = -0.8102105f;
                sa[31] = 1.2348076f;
            }
        }
    }

    // Neuron weights connecting Rectifier and Rectifier layer
    static class TwoInStart_Weight_2 implements java.io.Serializable {
        public static final float[] VALUES = new float[256];

        static {
            TwoInStart_Weight_2_0.fill(VALUES);
        }

        static final class TwoInStart_Weight_2_0 implements java.io.Serializable {
            static final void fill(float[] sa) {
                sa[0] = -0.093386255f;
                sa[1] = -0.75581855f;
                sa[2] = -0.5358923f;
                sa[3] = 0.56942755f;
                sa[4] = 0.6727372f;
                sa[5] = -1.0922955f;
                sa[6] = 0.49423495f;
                sa[7] = -0.22870076f;
                sa[8] = -0.26805845f;
                sa[9] = 0.019434096f;
                sa[10] = -0.21963798f;
                sa[11] = -1.1199158f;
                sa[12] = -0.31299523f;
                sa[13] = 0.017046135f;
                sa[14] = -1.0169525f;
                sa[15] = 0.36771145f;
                sa[16] = -0.2673661f;
                sa[17] = -0.6003518f;
                sa[18] = -0.03173028f;
                sa[19] = -0.46647558f;
                sa[20] = -0.13219576f;
                sa[21] = 0.21650656f;
                sa[22] = -0.9614502f;
                sa[23] = 0.093923196f;
                sa[24] = -0.42686078f;
                sa[25] = -0.81953466f;
                sa[26] = -0.18197642f;
                sa[27] = -0.34840384f;
                sa[28] = -0.084105775f;
                sa[29] = -0.82069254f;
                sa[30] = 0.16982587f;
                sa[31] = -0.41729316f;
                sa[32] = -0.41816396f;
                sa[33] = -0.28616324f;
                sa[34] = 0.27615884f;
                sa[35] = -0.3352787f;
                sa[36] = -0.113534585f;
                sa[37] = -0.088531025f;
                sa[38] = -0.30758753f;
                sa[39] = 0.29605436f;
                sa[40] = -0.31827337f;
                sa[41] = -0.14999025f;
                sa[42] = 0.27751645f;
                sa[43] = -0.36856082f;
                sa[44] = -0.50109434f;
                sa[45] = -0.46723232f;
                sa[46] = -0.47551614f;
                sa[47] = 0.222328f;
                sa[48] = 0.5004714f;
                sa[49] = 0.7667134f;
                sa[50] = 0.15145597f;
                sa[51] = 0.4143702f;
                sa[52] = 0.36122322f;
                sa[53] = 0.09821888f;
                sa[54] = 0.30368927f;
                sa[55] = 0.108507045f;
                sa[56] = 0.60570407f;
                sa[57] = 0.4593713f;
                sa[58] = -0.43923202f;
                sa[59] = 0.32659197f;
                sa[60] = 0.8779942f;
                sa[61] = 0.4221238f;
                sa[62] = 0.22915505f;
                sa[63] = -0.2594967f;
                sa[64] = -0.26935935f;
                sa[65] = -0.2662605f;
                sa[66] = 0.12237256f;
                sa[67] = -0.39622158f;
                sa[68] = -0.10550158f;
                sa[69] = -0.25041974f;
                sa[70] = 0.3666298f;
                sa[71] = -0.38162017f;
                sa[72] = 0.22549295f;
                sa[73] = 0.15405649f;
                sa[74] = -0.2090547f;
                sa[75] = 0.11130807f;
                sa[76] = -0.4789074f;
                sa[77] = -0.06067508f;
                sa[78] = -0.28581607f;
                sa[79] = -0.3836075f;
                sa[80] = 0.04447768f;
                sa[81] = 0.8197593f;
                sa[82] = -0.21524179f;
                sa[83] = 0.8644106f;
                sa[84] = 0.5003723f;
                sa[85] = 0.44148687f;
                sa[86] = 0.47799197f;
                sa[87] = -0.12725793f;
                sa[88] = 0.8220408f;
                sa[89] = 0.79232347f;
                sa[90] = -0.08338814f;
                sa[91] = 0.042276062f;
                sa[92] = 0.55747944f;
                sa[93] = 0.75062346f;
                sa[94] = 0.3738758f;
                sa[95] = 0.0072850185f;
                sa[96] = 0.61349726f;
                sa[97] = 0.99713f;
                sa[98] = -0.37495035f;
                sa[99] = 0.58731097f;
                sa[100] = -0.2692546f;
                sa[101] = 0.16000539f;
                sa[102] = 0.29632813f;
                sa[103] = 0.08267425f;
                sa[104] = 0.77314276f;
                sa[105] = 0.7976425f;
                sa[106] = 0.14192697f;
                sa[107] = 0.54032683f;
                sa[108] = 0.8569079f;
                sa[109] = 1.0216486f;
                sa[110] = -0.033634935f;
                sa[111] = 0.115192704f;
                sa[112] = 0.67317665f;
                sa[113] = 0.69794333f;
                sa[114] = 0.005194524f;
                sa[115] = 1.1519753f;
                sa[116] = 0.3201652f;
                sa[117] = -0.10002702f;
                sa[118] = 0.55796814f;
                sa[119] = 0.10444282f;
                sa[120] = 0.103606746f;
                sa[121] = 0.728582f;
                sa[122] = -0.2755823f;
                sa[123] = 0.35749f;
                sa[124] = 0.7900766f;
                sa[125] = 0.4482291f;
                sa[126] = 0.26131448f;
                sa[127] = 0.10941806f;
                sa[128] = -0.28492853f;
                sa[129] = 0.066668086f;
                sa[130] = -0.34475452f;
                sa[131] = -0.29937914f;
                sa[132] = 0.26971292f;
                sa[133] = -0.6835279f;
                sa[134] = -0.42240128f;
                sa[135] = 0.26878887f;
                sa[136] = -0.11564934f;
                sa[137] = -0.42518935f;
                sa[138] = 0.16480237f;
                sa[139] = -0.45814708f;
                sa[140] = -0.08300658f;
                sa[141] = -0.1258068f;
                sa[142] = 0.083231494f;
                sa[143] = 0.19307758f;
                sa[144] = -0.3099993f;
                sa[145] = 0.05700275f;
                sa[146] = -0.36111626f;
                sa[147] = -0.07830521f;
                sa[148] = -0.37959132f;
                sa[149] = -0.14827664f;
                sa[150] = -0.37059757f;
                sa[151] = -0.35642472f;
                sa[152] = 0.24044007f;
                sa[153] = -0.3586463f;
                sa[154] = 0.012320482f;
                sa[155] = 0.14337529f;
                sa[156] = -0.27807194f;
                sa[157] = -0.14628053f;
                sa[158] = -0.006903184f;
                sa[159] = -0.3885522f;
                sa[160] = -0.4568451f;
                sa[161] = -0.08003886f;
                sa[162] = 0.064522676f;
                sa[163] = -0.0366801f;
                sa[164] = 0.31747887f;
                sa[165] = -0.07882079f;
                sa[166] = -0.14188975f;
                sa[167] = -0.11562109f;
                sa[168] = -0.2868048f;
                sa[169] = -0.33510175f;
                sa[170] = -0.1327894f;
                sa[171] = -0.6209478f;
                sa[172] = -0.08047131f;
                sa[173] = -0.41500917f;
                sa[174] = -0.24357137f;
                sa[175] = -0.08196084f;
                sa[176] = 0.55851895f;
                sa[177] = 0.3927735f;
                sa[178] = 0.30208388f;
                sa[179] = 0.80991393f;
                sa[180] = -0.057115164f;
                sa[181] = -0.13769671f;
                sa[182] = 0.5653045f;
                sa[183] = -0.2870138f;
                sa[184] = 0.80371034f;
                sa[185] = 0.99840033f;
                sa[186] = -0.028187629f;
                sa[187] = 0.18475725f;
                sa[188] = 0.45276147f;
                sa[189] = 0.97642076f;
                sa[190] = 0.18718404f;
                sa[191] = -0.13077453f;
                sa[192] = -0.22807069f;
                sa[193] = -0.7058452f;
                sa[194] = -0.3292755f;
                sa[195] = -0.42611688f;
                sa[196] = -0.11557785f;
                sa[197] = 0.2475929f;
                sa[198] = -0.8762698f;
                sa[199] = -0.29283053f;
                sa[200] = -0.42406273f;
                sa[201] = -0.30770117f;
                sa[202] = 0.24095291f;
                sa[203] = 0.04220138f;
                sa[204] = -0.17637207f;
                sa[205] = -0.21151306f;
                sa[206] = -0.44892976f;
                sa[207] = 0.2911581f;
                sa[208] = 0.62464744f;
                sa[209] = 0.35502836f;
                sa[210] = -0.24942909f;
                sa[211] = 0.3467638f;
                sa[212] = -0.17776534f;
                sa[213] = 0.13988289f;
                sa[214] = 0.1949729f;
                sa[215] = 0.31698915f;
                sa[216] = 0.38152233f;
                sa[217] = 0.39320996f;
                sa[218] = -0.22338063f;
                sa[219] = 0.14173447f;
                sa[220] = 0.49978438f;
                sa[221] = 0.4336498f;
                sa[222] = 0.19959937f;
                sa[223] = 0.4155691f;
                sa[224] = -0.6516414f;
                sa[225] = 0.065827884f;
                sa[226] = -0.20653497f;
                sa[227] = -0.6652002f;
                sa[228] = 0.043035883f;
                sa[229] = -0.34489962f;
                sa[230] = -0.56202626f;
                sa[231] = 0.338897f;
                sa[232] = -0.1134552f;
                sa[233] = -0.2505983f;
                sa[234] = -0.18709666f;
                sa[235] = -0.68986124f;
                sa[236] = -0.429606f;
                sa[237] = -0.08754107f;
                sa[238] = -0.74048555f;
                sa[239] = 0.49703136f;
                sa[240] = -0.6166235f;
                sa[241] = -0.47864416f;
                sa[242] = 0.32129183f;
                sa[243] = -0.366481f;
                sa[244] = 0.34048063f;
                sa[245] = -0.11520242f;
                sa[246] = -0.40230033f;
                sa[247] = -0.18563257f;
                sa[248] = -0.20309709f;
                sa[249] = -0.3912713f;
                sa[250] = 0.019279776f;
                sa[251] = 0.07307176f;
                sa[252] = -0.41610205f;
                sa[253] = -0.85534984f;
                sa[254] = -0.27286512f;
                sa[255] = -0.2854672f;
            }
        }
    }

    // Neuron weights connecting Rectifier and Softmax layer
    static class TwoInStart_Weight_3 implements java.io.Serializable {
        public static final float[] VALUES = new float[32];

        static {
            TwoInStart_Weight_3_0.fill(VALUES);
        }

        static final class TwoInStart_Weight_3_0 implements java.io.Serializable {
            static final void fill(float[] sa) {
                sa[0] = 2.8924358f;
                sa[1] = 1.7359761f;
                sa[2] = -0.71677494f;
                sa[3] = -2.575845f;
                sa[4] = 2.2663155f;
                sa[5] = -1.1064641f;
                sa[6] = -2.7837753f;
                sa[7] = 0.10912442f;
                sa[8] = 0.73171246f;
                sa[9] = 1.7010088f;
                sa[10] = 1.6540498f;
                sa[11] = -2.8734088f;
                sa[12] = 0.61985934f;
                sa[13] = -0.45493215f;
                sa[14] = 1.6956584f;
                sa[15] = 1.3297068f;
                sa[16] = -3.5555267f;
                sa[17] = -0.106622495f;
                sa[18] = -1.365792f;
                sa[19] = 0.77417964f;
                sa[20] = 1.9411248f;
                sa[21] = 3.1157525f;
                sa[22] = 0.5553447f;
                sa[23] = 1.2411373f;
                sa[24] = -0.45913774f;
                sa[25] = 0.76655626f;
                sa[26] = 0.8125538f;
                sa[27] = -1.1988597f;
                sa[28] = 0.5883368f;
                sa[29] = 0.74303806f;
                sa[30] = -0.60345346f;
                sa[31] = -1.6653067f;
            }
        }
    }

    // The class representing training column names
    static class NamesHolder_TwoInStart implements java.io.Serializable {
        public static final String[] VALUES = new String[2];

        static {
            NamesHolder_TwoInStart_0.fill(VALUES);
        }

        static final class NamesHolder_TwoInStart_0 implements java.io.Serializable {
            static final void fill(String[] sa) {
                sa[0] = "RSSI MIDDLE_ORIGIN";
                sa[1] = "RSSI TRUNK_ORIGIN";
            }
        }
    }

    // The class representing column class
    static class TwoInStart_ColInfo_2 implements java.io.Serializable {
        public static final String[] VALUES = new String[2];

        static {
            TwoInStart_ColInfo_2_0.fill(VALUES);
        }

        static final class TwoInStart_ColInfo_2_0 implements java.io.Serializable {
            static final void fill(String[] sa) {
                sa[0] = "inside";
                sa[1] = "outside";
            }
        }
    }
}

