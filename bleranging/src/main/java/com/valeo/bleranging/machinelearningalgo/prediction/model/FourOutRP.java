/*
  Licensed under the Apache License, Version 2.0
    http://www.apache.org/licenses/LICENSE-2.0.html

  AUTOGENERATED BY H2O at 2017-05-19T16:08:46.761+02:00
  3.10.4.2
  
  Standalone prediction code with sample test data for DeepLearningModel named FourOutRP

  How to download, compile and execute:
      mkdir tmpdir
      cd tmpdir
      curl http://127.0.0.1:54321/3/h2o-genmodel.jar > h2o-genmodel.jar
      curl http://127.0.0.1:54321/3/Models.java/FourOutRP > FourOutRP.java
      javac -cp h2o-genmodel.jar -J-Xmx2g -J-XX:MaxPermSize=128m FourOutRP.java

     (Note:  Try java argument -XX:+PrintCompilation to show runtime JIT compiler behavior.)
*/

import hex.genmodel.GenModel;
import hex.genmodel.annotations.ModelPojo;

@ModelPojo(name = "FourOutRP", algorithm = "deeplearning")
public class FourOutRP extends GenModel {
    // Workspace for categorical offsets.
    public static final int[] CATOFFSETS = {0};
    // Number of neurons for each layer.
    public static final int[] NEURONS = {4, 16, 16, 2};
    // Neuron bias values.
    public static final double[][] BIAS = new double[][]{
      /* Input */ FourOutRP_Bias_0.VALUES,
      /* Rectifier */ FourOutRP_Bias_1.VALUES,
      /* Rectifier */ FourOutRP_Bias_2.VALUES,
      /* Softmax */ FourOutRP_Bias_3.VALUES
    };
    // Connecting weights between neurons.
    public static final float[][] WEIGHT = new float[][]{
      /* Input */ FourOutRP_Weight_0.VALUES,
      /* Rectifier */ FourOutRP_Weight_1.VALUES,
      /* Rectifier */ FourOutRP_Weight_2.VALUES,
      /* Softmax */ FourOutRP_Weight_3.VALUES
    };
    // Names of columns used by model.
    public static final String[] NAMES = NamesHolder_FourOutRP.VALUES;
    // Number of output classes included in training data response column.
    public static final int NCLASSES = 2;
    // Column domains. The last array contains domain of response column.
    public static final String[][] DOMAINS = new String[][]{
    /* RSSI LEFT_ORIGIN */ null,
    /* RSSI MIDDLE_ORIGIN */ null,
    /* RSSI RIGHT_ORIGIN */ null,
    /* RSSI TRUNK_ORIGIN */ null,
    /* class */ FourOutRP_ColInfo_4.VALUES
    };
    // Prior class distribution
    public static final double[] PRIOR_CLASS_DISTRIB = {0.6666666666666666, 0.3333333333333333};
    // Class distribution used for model building
    public static final double[] MODEL_CLASS_DISTRIB = null;
    // Thread-local storage for input neuron activation values.
    final double[] NUMS = new double[4];
    // Thread-local storage for neuron activation values.
    final double[][] ACTIVATION = new double[][]{
      /* Input */ FourOutRP_Activation_0.VALUES,
      /* Rectifier */ FourOutRP_Activation_1.VALUES,
      /* Rectifier */ FourOutRP_Activation_2.VALUES,
      /* Softmax */ FourOutRP_Activation_3.VALUES
    };

    public FourOutRP() {
        super(NAMES, DOMAINS);
    }

    public hex.ModelCategory getModelCategory() {
        return hex.ModelCategory.Binomial;
    }

    public boolean isSupervised() {
        return true;
    }

    public int nfeatures() {
        return 4;
    }

    public int nclasses() {
        return 2;
    }

    public String getUUID() {
        return Long.toString(5058792029997021538L);
    }

    // Pass in data in a double[], pre-aligned to the Model's requirements.
    // Jam predictions into the preds[] array; preds[0] is reserved for the
    // main prediction (class for classifiers or value for regression),
    // and remaining columns hold a probability distribution for classifiers.
    public final double[] score0(double[] data, double[] preds) {
        java.util.Arrays.fill(preds, 0);
        java.util.Arrays.fill(NUMS, 0);
        int i = 0, ncats = 0;
        final int n = data.length;
        for (; i < n; ++i) {
            NUMS[i] = Double.isNaN(data[i]) ? 0 : (data[i] - NORMSUB.VALUES[i]) * NORMMUL.VALUES[i];
        }
        java.util.Arrays.fill(ACTIVATION[0], 0);
        for (i = 0; i < NUMS.length; ++i) {
            ACTIVATION[0][CATOFFSETS[CATOFFSETS.length - 1] + i] = Double.isNaN(NUMS[i]) ? 0 : NUMS[i];
        }
        for (i = 1; i < ACTIVATION.length; ++i) {
            java.util.Arrays.fill(ACTIVATION[i], 0);
            int cols = ACTIVATION[i - 1].length;
            int rows = ACTIVATION[i].length;
            int extra = cols - cols % 8;
            int multiple = (cols / 8) * 8 - 1;
            int idx = 0;
            float[] a = WEIGHT[i];
            double[] x = ACTIVATION[i - 1];
            double[] y = BIAS[i];
            double[] res = ACTIVATION[i];
            for (int row = 0; row < rows; ++row) {
                double psum0 = 0, psum1 = 0, psum2 = 0, psum3 = 0, psum4 = 0, psum5 = 0, psum6 = 0, psum7 = 0;
                for (int col = 0; col < multiple; col += 8) {
                    int off = idx + col;
                    psum0 += a[off] * x[col];
                    psum1 += a[off + 1] * x[col + 1];
                    psum2 += a[off + 2] * x[col + 2];
                    psum3 += a[off + 3] * x[col + 3];
                    psum4 += a[off + 4] * x[col + 4];
                    psum5 += a[off + 5] * x[col + 5];
                    psum6 += a[off + 6] * x[col + 6];
                    psum7 += a[off + 7] * x[col + 7];
                }
                res[row] += psum0 + psum1 + psum2 + psum3;
                res[row] += psum4 + psum5 + psum6 + psum7;
                for (int col = extra; col < cols; col++)
                    res[row] += a[idx + col] * x[col];
                res[row] += y[row];
                idx += cols;
            }
            if (i < ACTIVATION.length - 1) {
                for (int r = 0; r < ACTIVATION[i].length; ++r) {
                    ACTIVATION[i][r] = Math.max(0, ACTIVATION[i][r]);
                }
            }
            if (i == ACTIVATION.length - 1) {
                double max = ACTIVATION[i][0];
                for (int r = 1; r < ACTIVATION[i].length; r++) {
                    if (ACTIVATION[i][r] > max) max = ACTIVATION[i][r];
                }
                double scale = 0;
                for (int r = 0; r < ACTIVATION[i].length; r++) {
                    ACTIVATION[i][r] = Math.exp(ACTIVATION[i][r] - max);
                    scale += ACTIVATION[i][r];
                }
                for (int r = 0; r < ACTIVATION[i].length; r++) {
                    if (Double.isNaN(ACTIVATION[i][r]))
                        throw new RuntimeException("Numerical instability, predicted NaN.");
                    ACTIVATION[i][r] /= scale;
                    preds[r + 1] = ACTIVATION[i][r];
                }
            }
        }
        preds[0] = hex.genmodel.GenModel.getPrediction(preds, PRIOR_CLASS_DISTRIB, data, 0.28389864377946);
        return preds;
    }

    static class NORMMUL implements java.io.Serializable {
        public static final double[] VALUES = new double[4];

        static {
            NORMMUL_0.fill(VALUES);
        }

        static final class NORMMUL_0 implements java.io.Serializable {
            static final void fill(double[] sa) {
                sa[0] = 0.11866567233167209;
                sa[1] = 0.15824955006676253;
                sa[2] = 0.1222082006580076;
                sa[3] = 0.1513724686439283;
            }
        }
    }

    static class NORMSUB implements java.io.Serializable {
        public static final double[] VALUES = new double[4];

        static {
            NORMSUB_0.fill(VALUES);
        }

        static final class NORMSUB_0 implements java.io.Serializable {
            static final void fill(double[] sa) {
                sa[0] = -83.59895833333333;
                sa[1] = -86.35083333333333;
                sa[2] = -84.19097222222223;
                sa[3] = -81.16666666666667;
            }
        }
    }

    // Neuron activation values for Input layer
    static class FourOutRP_Activation_0 implements java.io.Serializable {
        public static final double[] VALUES = new double[4];

        static {
            FourOutRP_Activation_0_0.fill(VALUES);
        }

        static final class FourOutRP_Activation_0_0 implements java.io.Serializable {
            static final void fill(double[] sa) {
                sa[0] = 0.0;
                sa[1] = 0.0;
                sa[2] = 0.0;
                sa[3] = 0.0;
            }
        }
    }

    // Neuron activation values for Rectifier layer
    static class FourOutRP_Activation_1 implements java.io.Serializable {
        public static final double[] VALUES = new double[16];

        static {
            FourOutRP_Activation_1_0.fill(VALUES);
        }

        static final class FourOutRP_Activation_1_0 implements java.io.Serializable {
            static final void fill(double[] sa) {
                sa[0] = 0.0;
                sa[1] = 0.0;
                sa[2] = 0.0;
                sa[3] = 0.0;
                sa[4] = 0.0;
                sa[5] = 0.0;
                sa[6] = 0.0;
                sa[7] = 0.0;
                sa[8] = 0.0;
                sa[9] = 0.0;
                sa[10] = 0.0;
                sa[11] = 0.0;
                sa[12] = 0.0;
                sa[13] = 0.0;
                sa[14] = 0.0;
                sa[15] = 0.0;
            }
        }
    }

    // Neuron activation values for Rectifier layer
    static class FourOutRP_Activation_2 implements java.io.Serializable {
        public static final double[] VALUES = new double[16];

        static {
            FourOutRP_Activation_2_0.fill(VALUES);
        }

        static final class FourOutRP_Activation_2_0 implements java.io.Serializable {
            static final void fill(double[] sa) {
                sa[0] = 0.0;
                sa[1] = 0.0;
                sa[2] = 0.0;
                sa[3] = 0.0;
                sa[4] = 0.0;
                sa[5] = 0.0;
                sa[6] = 0.0;
                sa[7] = 0.0;
                sa[8] = 0.0;
                sa[9] = 0.0;
                sa[10] = 0.0;
                sa[11] = 0.0;
                sa[12] = 0.0;
                sa[13] = 0.0;
                sa[14] = 0.0;
                sa[15] = 0.0;
            }
        }
    }

    // Neuron activation values for Softmax layer
    static class FourOutRP_Activation_3 implements java.io.Serializable {
        public static final double[] VALUES = new double[2];

        static {
            FourOutRP_Activation_3_0.fill(VALUES);
        }

        static final class FourOutRP_Activation_3_0 implements java.io.Serializable {
            static final void fill(double[] sa) {
                sa[0] = 0.0;
                sa[1] = 0.0;
            }
        }
    }

    // Neuron bias values for Input layer
    static class FourOutRP_Bias_0 implements java.io.Serializable {
        public static final double[] VALUES = null;
    }

    // Neuron bias values for Rectifier layer
    static class FourOutRP_Bias_1 implements java.io.Serializable {
        public static final double[] VALUES = new double[16];

        static {
            FourOutRP_Bias_1_0.fill(VALUES);
        }

        static final class FourOutRP_Bias_1_0 implements java.io.Serializable {
            static final void fill(double[] sa) {
                sa[0] = 0.22560766121848275;
                sa[1] = 0.15372589159207586;
                sa[2] = 0.3135117337965355;
                sa[3] = 0.726754307319793;
                sa[4] = -0.01257818271530255;
                sa[5] = -0.0345270413171031;
                sa[6] = 0.18065441527495968;
                sa[7] = 0.05614662637297226;
                sa[8] = -0.37395893061578667;
                sa[9] = 0.23162614814103494;
                sa[10] = 0.1854966906430693;
                sa[11] = 0.36324002139893685;
                sa[12] = 0.4557918903800423;
                sa[13] = 0.535309957596399;
                sa[14] = 0.11613706083192633;
                sa[15] = 0.6037688835075765;
            }
        }
    }

    // Neuron bias values for Rectifier layer
    static class FourOutRP_Bias_2 implements java.io.Serializable {
        public static final double[] VALUES = new double[16];

        static {
            FourOutRP_Bias_2_0.fill(VALUES);
        }

        static final class FourOutRP_Bias_2_0 implements java.io.Serializable {
            static final void fill(double[] sa) {
                sa[0] = 0.09071900082900639;
                sa[1] = 0.7414249277000722;
                sa[2] = 1.0150689014353882;
                sa[3] = 1.1348892554746977;
                sa[4] = 0.9734076232733486;
                sa[5] = 1.0433800191637954;
                sa[6] = 0.8228081341664425;
                sa[7] = 0.8387207626209138;
                sa[8] = 1.1888945463491867;
                sa[9] = 1.4316837105896965;
                sa[10] = 0.8859621943513585;
                sa[11] = 0.9801540118087614;
                sa[12] = 0.8632238822131026;
                sa[13] = 1.5851954509035047;
                sa[14] = 0.907822404374512;
                sa[15] = 0.9412950913759738;
            }
        }
    }

    // Neuron bias values for Softmax layer
    static class FourOutRP_Bias_3 implements java.io.Serializable {
        public static final double[] VALUES = new double[2];

        static {
            FourOutRP_Bias_3_0.fill(VALUES);
        }

        static final class FourOutRP_Bias_3_0 implements java.io.Serializable {
            static final void fill(double[] sa) {
                sa[0] = -0.11510526383500873;
                sa[1] = 0.07518642856432976;
            }
        }
    }

    static class FourOutRP_Weight_0 implements java.io.Serializable {
        public static final float[] VALUES = null;
    }

    // Neuron weights connecting Input and Rectifier layer
    static class FourOutRP_Weight_1 implements java.io.Serializable {
        public static final float[] VALUES = new float[64];

        static {
            FourOutRP_Weight_1_0.fill(VALUES);
        }

        static final class FourOutRP_Weight_1_0 implements java.io.Serializable {
            static final void fill(float[] sa) {
                sa[0] = -0.11520986f;
                sa[1] = -0.06258659f;
                sa[2] = -0.22662264f;
                sa[3] = 0.17109133f;
                sa[4] = 0.2085097f;
                sa[5] = -0.14900704f;
                sa[6] = -0.3944724f;
                sa[7] = 0.567387f;
                sa[8] = -0.43699822f;
                sa[9] = -0.034925506f;
                sa[10] = 0.40046677f;
                sa[11] = 0.48661903f;
                sa[12] = 0.4231354f;
                sa[13] = -0.20536877f;
                sa[14] = 0.18797854f;
                sa[15] = -0.73471326f;
                sa[16] = 0.6211104f;
                sa[17] = 0.4702543f;
                sa[18] = 0.50326955f;
                sa[19] = 0.6123396f;
                sa[20] = 0.39824635f;
                sa[21] = 0.2170081f;
                sa[22] = 0.23500705f;
                sa[23] = -0.42270482f;
                sa[24] = 0.17948908f;
                sa[25] = -0.7595016f;
                sa[26] = -0.19052206f;
                sa[27] = 0.2054309f;
                sa[28] = -0.35827315f;
                sa[29] = -0.072887264f;
                sa[30] = -0.11261658f;
                sa[31] = 0.03125676f;
                sa[32] = -1.0430093f;
                sa[33] = -0.15657994f;
                sa[34] = 0.69088155f;
                sa[35] = 0.13017882f;
                sa[36] = -0.4704266f;
                sa[37] = 0.0124214245f;
                sa[38] = -0.35613704f;
                sa[39] = 0.1543175f;
                sa[40] = 0.135297f;
                sa[41] = -0.37546661f;
                sa[42] = -0.41100612f;
                sa[43] = -0.0348307f;
                sa[44] = -0.4980057f;
                sa[45] = 1.0359992f;
                sa[46] = 0.09697779f;
                sa[47] = -0.44906527f;
                sa[48] = 0.0058672195f;
                sa[49] = 0.69231975f;
                sa[50] = 0.3494101f;
                sa[51] = 0.26068896f;
                sa[52] = -0.7904423f;
                sa[53] = -0.17316777f;
                sa[54] = -0.71140903f;
                sa[55] = -0.43206313f;
                sa[56] = 0.122704156f;
                sa[57] = -0.26874247f;
                sa[58] = 0.09511733f;
                sa[59] = 0.5062184f;
                sa[60] = 0.30056226f;
                sa[61] = -0.8542191f;
                sa[62] = 0.19620068f;
                sa[63] = 0.2200503f;
            }
        }
    }

    // Neuron weights connecting Rectifier and Rectifier layer
    static class FourOutRP_Weight_2 implements java.io.Serializable {
        public static final float[] VALUES = new float[256];

        static {
            FourOutRP_Weight_2_0.fill(VALUES);
        }

        static final class FourOutRP_Weight_2_0 implements java.io.Serializable {
            static final void fill(float[] sa) {
                sa[0] = -0.71123403f;
                sa[1] = 0.12901698f;
                sa[2] = -0.0884663f;
                sa[3] = -0.45225543f;
                sa[4] = 0.3605256f;
                sa[5] = -0.08854384f;
                sa[6] = -0.15433282f;
                sa[7] = -0.051549304f;
                sa[8] = 0.028355917f;
                sa[9] = 0.17477167f;
                sa[10] = -0.5665542f;
                sa[11] = 0.005218601f;
                sa[12] = -0.79374814f;
                sa[13] = 0.05675131f;
                sa[14] = 0.066944025f;
                sa[15] = 0.21399765f;
                sa[16] = -0.19435796f;
                sa[17] = 0.069114015f;
                sa[18] = -0.070529f;
                sa[19] = -0.5227768f;
                sa[20] = 0.40342033f;
                sa[21] = -0.39800847f;
                sa[22] = -0.59907806f;
                sa[23] = -0.023712894f;
                sa[24] = 0.06950143f;
                sa[25] = -0.2889994f;
                sa[26] = -0.052762818f;
                sa[27] = 0.40347132f;
                sa[28] = 0.034770563f;
                sa[29] = 0.47213843f;
                sa[30] = -0.115509056f;
                sa[31] = -0.34347194f;
                sa[32] = 0.15798329f;
                sa[33] = -0.7085317f;
                sa[34] = -0.6774797f;
                sa[35] = 0.08933174f;
                sa[36] = -0.082801774f;
                sa[37] = 0.3439997f;
                sa[38] = -0.10413778f;
                sa[39] = -0.69479495f;
                sa[40] = 0.1266366f;
                sa[41] = -0.34747076f;
                sa[42] = -0.013551451f;
                sa[43] = -0.054455172f;
                sa[44] = -0.8746602f;
                sa[45] = -0.5431921f;
                sa[46] = 0.15958723f;
                sa[47] = -0.2253229f;
                sa[48] = 0.32236576f;
                sa[49] = -0.58324504f;
                sa[50] = 0.13847741f;
                sa[51] = -0.26716882f;
                sa[52] = -0.2182935f;
                sa[53] = -0.8064005f;
                sa[54] = 0.15686466f;
                sa[55] = 0.3096856f;
                sa[56] = -0.26484755f;
                sa[57] = 0.34113473f;
                sa[58] = 0.3806101f;
                sa[59] = -0.27939436f;
                sa[60] = 0.5466789f;
                sa[61] = -0.24892476f;
                sa[62] = 0.41608042f;
                sa[63] = -0.281906f;
                sa[64] = -0.33605713f;
                sa[65] = -0.52917486f;
                sa[66] = -0.027884208f;
                sa[67] = -0.5118987f;
                sa[68] = -0.020010961f;
                sa[69] = -0.6112583f;
                sa[70] = -0.08902068f;
                sa[71] = -0.3921192f;
                sa[72] = -1.2365664f;
                sa[73] = -0.24577606f;
                sa[74] = -0.61997515f;
                sa[75] = 0.4853506f;
                sa[76] = 0.07788022f;
                sa[77] = 0.20870411f;
                sa[78] = -0.50834453f;
                sa[79] = 0.35500792f;
                sa[80] = -0.13799338f;
                sa[81] = 0.40215862f;
                sa[82] = 0.6574151f;
                sa[83] = 0.23496711f;
                sa[84] = 0.38026166f;
                sa[85] = 0.027039336f;
                sa[86] = -0.3280678f;
                sa[87] = -0.26703385f;
                sa[88] = 0.29953215f;
                sa[89] = -0.17218241f;
                sa[90] = -0.21395835f;
                sa[91] = 0.0056343214f;
                sa[92] = 0.018568128f;
                sa[93] = 0.049111556f;
                sa[94] = 0.15551479f;
                sa[95] = 0.4856426f;
                sa[96] = -0.129757f;
                sa[97] = -0.55805665f;
                sa[98] = -0.10820752f;
                sa[99] = 0.06613125f;
                sa[100] = -0.2843992f;
                sa[101] = -0.17789319f;
                sa[102] = 0.4300006f;
                sa[103] = 0.34167853f;
                sa[104] = 0.24298838f;
                sa[105] = 0.27341592f;
                sa[106] = 0.07984895f;
                sa[107] = 0.11388574f;
                sa[108] = 0.19176242f;
                sa[109] = 0.27973258f;
                sa[110] = 0.4233294f;
                sa[111] = -0.34776533f;
                sa[112] = 0.091787614f;
                sa[113] = -0.66187036f;
                sa[114] = -0.54667294f;
                sa[115] = -0.07272227f;
                sa[116] = 0.107661225f;
                sa[117] = -0.28672886f;
                sa[118] = 0.32220742f;
                sa[119] = 0.18196546f;
                sa[120] = 0.4414116f;
                sa[121] = -0.11251747f;
                sa[122] = 0.30022237f;
                sa[123] = -0.15035987f;
                sa[124] = -0.020992009f;
                sa[125] = 0.23341793f;
                sa[126] = -0.23598479f;
                sa[127] = 0.026353268f;
                sa[128] = 0.19027945f;
                sa[129] = -0.66269326f;
                sa[130] = 0.14674509f;
                sa[131] = -0.06658277f;
                sa[132] = 0.12124472f;
                sa[133] = -0.09956014f;
                sa[134] = -0.018561795f;
                sa[135] = -0.50191534f;
                sa[136] = -0.07294983f;
                sa[137] = -0.14592932f;
                sa[138] = -0.4171354f;
                sa[139] = -0.13030641f;
                sa[140] = 0.085836954f;
                sa[141] = -0.21849471f;
                sa[142] = 0.16394813f;
                sa[143] = -0.15414202f;
                sa[144] = 0.042820785f;
                sa[145] = -0.38769487f;
                sa[146] = -0.22387014f;
                sa[147] = -0.23799227f;
                sa[148] = 0.17281789f;
                sa[149] = 0.66814584f;
                sa[150] = -0.54007304f;
                sa[151] = -0.024510875f;
                sa[152] = -0.49279088f;
                sa[153] = 0.23817986f;
                sa[154] = -0.42976713f;
                sa[155] = -0.24876703f;
                sa[156] = -0.06310248f;
                sa[157] = -1.0625108f;
                sa[158] = 0.23239654f;
                sa[159] = 0.10960286f;
                sa[160] = 0.0905071f;
                sa[161] = -0.6506374f;
                sa[162] = -0.6195873f;
                sa[163] = 0.21841174f;
                sa[164] = 0.071087f;
                sa[165] = -0.23437616f;
                sa[166] = 0.21898434f;
                sa[167] = 0.33913675f;
                sa[168] = 0.5743004f;
                sa[169] = -0.58299667f;
                sa[170] = 0.06469678f;
                sa[171] = 0.15582937f;
                sa[172] = -0.2472191f;
                sa[173] = -0.21245052f;
                sa[174] = 0.120874405f;
                sa[175] = 0.16516136f;
                sa[176] = 0.15309812f;
                sa[177] = -0.46975243f;
                sa[178] = -0.5004011f;
                sa[179] = 0.06821675f;
                sa[180] = -0.38189617f;
                sa[181] = -0.6884416f;
                sa[182] = 0.2208427f;
                sa[183] = 0.019825794f;
                sa[184] = 0.25843385f;
                sa[185] = -0.2554228f;
                sa[186] = 0.22512792f;
                sa[187] = 0.2042474f;
                sa[188] = 0.3951472f;
                sa[189] = 0.23811539f;
                sa[190] = 0.43647382f;
                sa[191] = -0.32239816f;
                sa[192] = -0.7559247f;
                sa[193] = -0.44669563f;
                sa[194] = -0.057490762f;
                sa[195] = 0.41850284f;
                sa[196] = -0.24577336f;
                sa[197] = 0.86177194f;
                sa[198] = 0.43416265f;
                sa[199] = -0.25157613f;
                sa[200] = -1.0056889f;
                sa[201] = -0.205269f;
                sa[202] = -0.5099066f;
                sa[203] = -0.39939457f;
                sa[204] = -0.13898382f;
                sa[205] = -0.5210016f;
                sa[206] = -0.23015206f;
                sa[207] = 0.6432064f;
                sa[208] = 0.1307286f;
                sa[209] = -0.5744725f;
                sa[210] = -0.2036448f;
                sa[211] = -0.32168102f;
                sa[212] = -0.5027279f;
                sa[213] = -0.5400306f;
                sa[214] = -0.36060402f;
                sa[215] = 0.7757491f;
                sa[216] = -0.6459706f;
                sa[217] = 0.04306978f;
                sa[218] = -0.3573202f;
                sa[219] = 0.32402587f;
                sa[220] = -0.74459225f;
                sa[221] = -0.40966335f;
                sa[222] = -0.56055397f;
                sa[223] = -0.0222219f;
                sa[224] = 0.47781518f;
                sa[225] = -0.051675912f;
                sa[226] = -0.2840296f;
                sa[227] = 0.38969904f;
                sa[228] = -0.18826821f;
                sa[229] = 0.021410573f;
                sa[230] = 0.09133602f;
                sa[231] = 0.42106876f;
                sa[232] = 0.060579695f;
                sa[233] = -0.066682756f;
                sa[234] = -0.0143721225f;
                sa[235] = 0.21558203f;
                sa[236] = -0.1745804f;
                sa[237] = 0.025145102f;
                sa[238] = 0.24933462f;
                sa[239] = -0.5116706f;
                sa[240] = 0.20472063f;
                sa[241] = 0.03168362f;
                sa[242] = 0.5849556f;
                sa[243] = 0.09895468f;
                sa[244] = 0.61941504f;
                sa[245] = 0.4314527f;
                sa[246] = 0.035327405f;
                sa[247] = 0.11372568f;
                sa[248] = 0.33184198f;
                sa[249] = -0.04050696f;
                sa[250] = -0.12878273f;
                sa[251] = -0.20321928f;
                sa[252] = -0.27451247f;
                sa[253] = 0.11056347f;
                sa[254] = -0.05350335f;
                sa[255] = 0.39985698f;
            }
        }
    }

    // Neuron weights connecting Rectifier and Softmax layer
    static class FourOutRP_Weight_3 implements java.io.Serializable {
        public static final float[] VALUES = new float[32];

        static {
            FourOutRP_Weight_3_0.fill(VALUES);
        }

        static final class FourOutRP_Weight_3_0 implements java.io.Serializable {
            static final void fill(float[] sa) {
                sa[0] = -0.7926241f;
                sa[1] = -2.017888f;
                sa[2] = 3.211937f;
                sa[3] = 2.2381582f;
                sa[4] = -2.2406764f;
                sa[5] = -2.2363086f;
                sa[6] = 0.32917145f;
                sa[7] = 1.5206361f;
                sa[8] = 0.62948275f;
                sa[9] = -0.098403156f;
                sa[10] = 1.6090578f;
                sa[11] = 1.19126f;
                sa[12] = 1.534992f;
                sa[13] = -2.2530427f;
                sa[14] = 1.8535359f;
                sa[15] = -0.15806206f;
                sa[16] = -0.8930188f;
                sa[17] = 1.5396457f;
                sa[18] = 0.32480654f;
                sa[19] = -1.080008f;
                sa[20] = 2.6141396f;
                sa[21] = -0.0837422f;
                sa[22] = -1.7304487f;
                sa[23] = -0.035235733f;
                sa[24] = -0.633717f;
                sa[25] = -2.9259908f;
                sa[26] = -0.30706775f;
                sa[27] = -0.78259164f;
                sa[28] = 2.437662f;
                sa[29] = -0.9057038f;
                sa[30] = 1.1343201f;
                sa[31] = 0.9693376f;
            }
        }
    }

    // The class representing training column names
    static class NamesHolder_FourOutRP implements java.io.Serializable {
        public static final String[] VALUES = new String[4];

        static {
            NamesHolder_FourOutRP_0.fill(VALUES);
        }

        static final class NamesHolder_FourOutRP_0 implements java.io.Serializable {
            static final void fill(String[] sa) {
                sa[0] = "RSSI LEFT_ORIGIN";
                sa[1] = "RSSI MIDDLE_ORIGIN";
                sa[2] = "RSSI RIGHT_ORIGIN";
                sa[3] = "RSSI TRUNK_ORIGIN";
            }
        }
    }

    // The class representing column class
    static class FourOutRP_ColInfo_4 implements java.io.Serializable {
        public static final String[] VALUES = new String[2];

        static {
            FourOutRP_ColInfo_4_0.fill(VALUES);
        }

        static final class FourOutRP_ColInfo_4_0 implements java.io.Serializable {
            static final void fill(String[] sa) {
                sa[0] = "far";
                sa[1] = "near";
            }
        }
    }
}
